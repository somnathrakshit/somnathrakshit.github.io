<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.7.0"><meta name=author content="Somnath Rakshit"><meta name=description content="Masters student (Data Science track) at the School of Information, UT Austin"><link rel=alternate hreflang=en-us href=https://somnathrakshit.github.io/tags/deep-learning/><meta name=theme-color content=#2962ff><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/academic.css><script async src="https://www.googletagmanager.com/gtag/js?id=UA-107696056-2"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
function trackOutboundLink(url,target){gtag('event','click',{'event_category':'outbound','event_label':url,'transport_type':'beacon','event_callback':function(){if(target!=='_blank'){document.location=url;}}});console.debug("Outbound link clicked: "+url);}
function onClickCallback(event){if((event.target.tagName!=='A')||(event.target.host===window.location.host)){return;}
trackOutboundLink(event.target,event.target.getAttribute('target'));}
gtag('js',new Date());gtag('config','UA-107696056-2',{});document.addEventListener('click',onClickCallback,false);</script><link rel=alternate href=/tags/deep-learning/index.xml type=application/rss+xml title="Somnath Rakshit"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu8f513581b82a7ea9f3a68e0c5d348cec_18530_32x32_fill_lanczos_center_2.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu8f513581b82a7ea9f3a68e0c5d348cec_18530_192x192_fill_lanczos_center_2.png><link rel=canonical href=https://somnathrakshit.github.io/tags/deep-learning/><meta property=twitter:card content=summary_large_image><meta property=twitter:site content=@_SomnathRakshit><meta property=twitter:creator content=@_SomnathRakshit><meta property=og:site_name content="Somnath Rakshit"><meta property=og:url content=https://somnathrakshit.github.io/tags/deep-learning/><meta property=og:title content="deep learning | Somnath Rakshit"><meta property=og:description content="Masters student (Data Science track) at the School of Information, UT Austin"><meta property=og:image content=https://somnathrakshit.github.io/img/avatar.jpg><meta property=twitter:image content=https://somnathrakshit.github.io/img/avatar.jpg><meta property=og:locale content=en-us><meta property=og:updated_time content=2019-12-10T16:16:12-06:00><title>deep learning | Somnath Rakshit</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Somnath Rakshit</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Somnath Rakshit</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/project><span>Projects</span></a></li><li class=nav-item><a class=nav-link href=/publication><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/post><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/files/Somnath_Rakshit_Resume.pdf><span>Resume</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=#><i class="fas fa-search" aria-hidden=true></i></a></li><li class=nav-item><a class="nav-link js-dark-toggle" href=#><i class="fas fa-moon" aria-hidden=true></i></a></li></ul></div></nav><div class="universal-wrapper pt-3"><h1>deep learning</h1></div><div class=universal-wrapper><div><h2><a href=/publication/relevance-prediction-eye-movements-chiir-2020/>Relevance Prediction from Eye-movements Using Semi-interpretable Convolutional Neural Networks</a></h2><div class=article-style>We propose an image-classification method to predict the perceived-relevance of text documents from eye-movements. We conduct an eye-tracking study where participants read short news articles, and rate them as relevant or irrelevant for answering a trigger question. We encode participants' eye-movement scanpaths as images, and use these images to train a convolutional neural network classifier. The classifier is then used to predict the perceived-relevance of news article from the scanpath images. This method is content-independent, and the classifier does not require knowledge of the screen-content, or the participant's information-task. Even with little data, the image classifier can predict perceived-relevance with up to 80% accuracy. When compared to similar eye-tracking studies from the literature, the scanpath image classifier outperforms previously reported metrics by appreciable margins. We also attempt to interpret how the image classifier differentiates between scanpaths on relevant and irrelevant documents.</div></div><div><h2><a href=/publication/chexray/>Deep Learning for Detection and Localization of Thoracic Diseases using Chest X-Ray Imagery</a></h2><div class=article-style>Classification of diseases from biomedical images is a fast growing emerging field of research. In this regard, chest X-Rays (CXR) are one of the most widely used medical images to diagnose common heart and lung diseases where previous works have explored the usage of various pre-trained deep learning models to perform the classification. However, these models are very deep, thus use large number of parameters. Moreover, it is still not possible to find readily available access to a practicing radiologist for proper diagnosis from an X-Ray image of chest. Hence, this fact motivated us to conduct this research with the aim to classify CXR images in an automated manner with smaller number of parameters during training for 14 different categories of thoracic diseases and produce heatmap for the corresponding image in order to show the location of abnormality. For the purpose of classification, transfer learning is used with the pre-trained network of Resnet18, while the heatmaps are generated using pooling along the channel dimension and then computing the average of class-wise features. The proposed model contains less parameters to train and provides better performance than the other models present in the literature. The trained model is then validated both quantitatively and visually by producing localized images in the form of heatmaps of the CXR images. Moreover, the dataset and code of this work are provided online.</div></div><div><h2><a href=/publication/potato-leaves-transfer-learning/>Detection of Diseases in Potato Leaves using Transfer Learning</a></h2><div class=article-style>The problem of food shortage has grown rampant in the recent times in developing countries. In a tropical country like India, potato is one of the major staple food that is eaten throughout the year. Recently the production of potato is falling short due to various diseases like Early Blight and Late Blight which cause a huge loss of the cropped plants. This also leads to a major loss in the national economy as well. The emergence of deep learning has affected many fields of machine learning research. Since it is not required in deep learning to develop hand-crafted features, it has found widespread adoption in the scientific community. To tackle the need for a huge amount of data for deep learning, another heavily implemented technique is used, namely, transfer learning, to make the training process faster and more accurate with a relatively small dataset at hand. The performance of the model is demonstrated both quantitatively by computing the accuracy metric as well as visually. The model is lightweight and robust and thus can be added to an application in a handheld device like smartphone so that crop growers could spot the disease affected crops on the go and save them from getting ruined.</div></div><div><h2><a href=/publication/breast-cancer-integrated-sae/>Deep Learning for Integrated Analysis of Breast Cancer Subtype Specific Multi-omics Data</a></h2><div class=article-style>In this work, it is seen that deep learning technique such as stacked autoencoder can be useful in reducing the dimension of a high dimensional multi-omics data. The performance obtained using this architecture is better than the other methods as shown here. Besides, some genes are identified which are in the pathways of breast cancer, as determined by the deep selection of features and the Bonferroni correction of p-values of the result of the one-sample t-test.</div></div><div><h2><a href=/project/neural-style-transfer/>Neural Style Transfer</a></h2><div class=article-style>Implemented the neural style transfer algortihm implemented by Gatys et al. (2016) in PyTorch. This technique allows us to take an input image and perform its reproduction in a new artistic style.</div></div><div><h2><a href=/project/fundus-image-localization/>Detection and Localisation of Diabetic Retinopathy</a></h2><div class=article-style>Automated classification and localization of diabetic retinopathy was performed using Keras in fundus images. This work demonstrates that it is possible to obtain performance comparable to the state of the art performance in this task using a deep learning model with much less parameters.</div></div><div><h2><a href=/project/identify-land-pattern-keras/>Identifying Land Patterns from Satellite Imagery in Amazon Rainforest using Deep Learning</a></h2><div class=article-style>Multi label classification of land patterns in Amazon Rainforests using Keras. The results obtained demonstrate state of the art performance.</div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/highlight.min.js integrity="sha256-1zu+3BnLYV9LdiY85uXMzii3bdrkelyp37e0ZyTAQh0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.10/languages/python.min.js></script><script>const code_highlighting=true;</script><script>const isSiteThemeDark=false;</script><script>const search_config={"indexURI":"/index.json","minLength":1,"threshold":0.3};const i18n={"no_results":"No results found","placeholder":"Search...","results":"results found"};const content_type={'post':"Posts",'project':"Projects",'publication':"Publications",'talk':"Talks"};</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script src=/js/academic.min.a8d7005002cb4a052fd6d721e83df9ba.js></script><div class=container><footer class=site-footer><p class=powered-by>&copy; Somnath Rakshit, 2020 &middot; .
<span class=float-right aria-hidden=true><a href=# id=back_to_top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&times;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i>Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i>Download</a><div id=modal-error></div></div></div></div></div></body></html>